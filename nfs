#!/usr/bin/env python
#-*- coding:utf-8 -*-
'''
nfs 网络文件系统 network file system
    功能是通过网络让不同的及其系统之间可以彼此共享文件或目录，nfs客户端（一般为应用服务器，如web）可以通过挂载的方式将nfs服务器端共享的数据文件目录挂载到nfs客户端本地系统的某一挂载点下，从本地nfs客户端的机器看来，nfs服务器共享的目录就好像是自己的磁盘分区或目录一样

图7，图8

    nfs一般用来存储共享视频，图片，附件等静态资源文件（对于用户上传的文件都放到nfs里面），是当前互联网系统架构中常用的服务之一，特别是中小公司应用频率很高,大公司或门户用MFS,GFS,FASTFS分布式系统,淘宝也在用nfs,nfs性能不是特别高
    中小企业一般不会买存储，大公司业务发展快，可能会临时买存储顶一下，并发继续加大可能存储扩展就相对费劲，价格成几何级数增加，淘宝就替换了很多硬件设备集群软件，用lvs+haproxy替换了netscaler,用fastfs,tfs替换了netapp,emc存储

nfs 使用端口，协议传输数据
    nfs的端口是随机选择的，不固定
    nfs客户端通过rpc（远程过程调用）协议/服务 来实现传输数据
RPC协议/服务
    NFS支持的功能较多，不同功能利用不同程序启动，程序多端口就多，所有NFS端口才无法固定，随机启用小于1024的端口来做数据传输使用，客户端和服务端链接就出现困扰了，不知道端口是什么
    解决上述问题就利用RPC,RPC功能就是记录每个NFS功能和对应的端口号，当客户端请求服务端时候，把对应信息发给客户端，让客户端可以连接到正确的端口上，RPC类似服务端和客户端之间的中介
RPC如何知道NFS的端口
    NFS服务端启动时会随机去用数个端口，并主动向RPC服务注册去用的端口信息，这杨RPC服务就知道了每个端口对应的NFS功能，然后RPC服务使用固定的端口111来监听NFS客户端的请求，并将正确的NFS端口应答给NFS客户端，这样，就能进行数据传输了  图9

强调：
    启动NFS server之前，首先要启动RPC服务（centos5.8下为portmap服务，centos6.4下为rpcbind服务），否则NFS server 就无法想RPC注册。另外RPC服务重启，原来已经注册好的端口数据就会丢失，因此，此时RPC管理的NFS程序也需要重新启动以重新向RPC注册，特别注意，一般修改NFS配置后，是不需要重启NFS的，直接在命令行执行/etc/init.d/nfs reload或 exportfs -rv 即可使修改的 /etc/exports 生效

安装部署NFS
    环境准备

客户端 需要RPC服务进程，不需要NFS服务进程
服务端 需要RPC服务进程，需要NFS服务进程

cat /etc/redhat-release  看系统发行版本
uname -n
uname -r
uname -m
uname -a

软件两个：
sudo yum install nfs-utils  即可同时安装portmap rpcbind

1、nfs-utils   NFS主程序
    包括rpc.nfsd、rpc.mountd、两个daemons 和相关文档说明及执行命令的文件等
2、portman: centos5.X 下面的RPC主程序（centos6.4下为rpcbind）
    nfs可以被视为一个rpc程序，在启动任何一个rpc程序之前，需要做好端口映射工作，这个映射工作就是有portman(或rpcbind)服务来完成，因此 NFS服务启动前必须先启动portmap服务

查看默认软件包

rpm -aq nfs-utils portman  或rpm -aq nfs-utils rpcbind

启动nfs服务
启动portmap(centos6.x下为rpcbind)
    nfs服务都是基于rpc协议（使用的端口号111），所以先要确保portmap(或rpcbind)服务已经启动
service portmap(或rpcbind) status 查看状态
service portmap(或rpcbind) start
service portmap(或rpcbind) status

rpcinfo -p localhost  查看rpc信息

启动nfs
sudo service nfs status
sudo service nfs start
sudo service nfs status
rpcinfo -p localhost  查看nfs向rpc注册的端口信息

ps -ef 查看进程
ps -ef |egrep "rpc|nfs" 多过滤

    nfs服务的主要任务是进行文件共享，文件系统共享与权限有关，所以nfs服务启动时最少需要两个daemons,一个管理client端是否能够登入的问题，另一个管理client能够取得权限，如果还需要quota的话，还要加载rpc.rquotad程序

[dean@6.4-121 ~]$ps -ef |egrep "rpc|nfs"
rpc       1398     1  0 12:45 ?        00:00:00 rpcbind
root      1494     2  0 12:50 ?        00:00:00 [rpciod/0]
root      1502     1  0 12:50 ?        00:00:00 rpc.mountd
root      1508     2  0 12:50 ?        00:00:00 [nfsd4]
root      1509     2  0 12:50 ?        00:00:00 [nfsd4_callbacks]
root      1510     2  0 12:50 ?        00:00:00 [nfsd]
root      1511     2  0 12:50 ?        00:00:00 [nfsd]
root      1512     2  0 12:50 ?        00:00:00 [nfsd]
root      1513     2  0 12:50 ?        00:00:00 [nfsd]
root      1514     2  0 12:50 ?        00:00:00 [nfsd]
root      1515     2  0 12:50 ?        00:00:00 [nfsd]
root      1516     2  0 12:50 ?        00:00:00 [nfsd]
root      1517     2  0 12:50 ?        00:00:00 [nfsd]
root      1540     1  0 12:50 ?        00:00:00 rpc.idmapd
dean      1578  1214  0 12:56 pts/0    00:00:00 egrep rpc|nfs

1、nfsd(rpc.nfsd)
    这个daemon（守护进程）的主要功能是管理client端是否能够登入主机，其中还包含登入者的ID判别
2、rpc.mountd
    这个daemon 的主要功能是管理nfs的文件系统，当client端顺利通过rpc.nfsd登入主机后，在它可以使用nfs服务器提供数据前，还会经过文件使用权限（就是-rwxrwxrwx与owner,group那几个权限）的认证程序，它会去读nfs的配置文件/etc/exports来对比client的权限，当通过这一关后，client端就可以取得nfs文件的权限,注意，这个文件也是我们用来管理nfs共享目录的使用权限与安全的设置的地方
3、nfs 启动 的rpc daemons
    nfs启动时想rpc注册，所以nfs服务器被称为rpc server 之一，那么nfs是关于文件系统的服务，文件系统与权限有关，所以至少需要两个daemons
    a.rpc.nfsd  控制客户端是否能够登入问题
    b.rpc.mountd 管理客户端能够取得的权限认证程序，它会读取nfs配置文件 /etc/exports 来比对客户端的权限
    c.rpc.lockd( 非必要) 可用来解锁文件，用于多客户端同时写入
    d.rpc.statd(非必要) 检查文件的一致性，与rpc.lockd有关 c,d两个服务需要客户端服务端同时开启才行

小技巧：对于使用rpm包安装的软件，命令service nfs start的启动方式等同于/etc/init.d/nfs start  但推荐/etc/init.d/nfs start 原因是可以使用tab补全，而service 则需要完全手敲，适用于大多数用rpm包安装的其他软件的启动


配置nfs等服务开启启动
chkconfig nfs on
chkconfig portmap(rpcbind) on
工作中不建议这样直接设置，要把启动命令放到/etc/rc.local 中，全部开机启动命令都这样放，好管理
    vim /etc/rc.local
lrwxrwxrwx. 1 root root 13 Jul 29 13:37 /etc/rc.local -> rc.d/rc.local
        #描述信息
        /etc/init.d/portman(rpcbind) start
        /etc/init.d/nfs start

规范  
/rc.d/rc.local 需要备份，定时任务需要备份
开机任务统一放到/etc/rc.d/rc.local


查看结果
    chkconfig --list nfs
    chkconfig --list portmap(rpcbind)

配置nfs配置文件
nfs默认配置文件在 /etc/exports
    centos上nfs默认配置文件是存在的，但内容为空，需要自行配置内容，有的linux发行版可能不提供/etc/exports 需要手动创建
exports文件格式
    /etc/exports 文件格式：
nfs服务端共享目录 nfs客户端地址1（参1，参2。。。）客户端地址2（参1，参2。。。）
    man exports
1、nfs共享的目录  服务端的共享的实际目录，使用绝对地址
2、客户端地址   可以为单独的ip地址 或者主机名，域名等，也可以为整个网段地址，还可以用‘*’ 匹配所有客户端服务器可以访问，这里所谓的客户端一般来说是前端的业务服务器，例如 web服务
3、参数集  对授权的客户端的访问权限设置

表格说明
    客户端地址              具体例子                说明
授权单一客户端访问nfs       10.0.0.30           一般情况下，生产环境中此配置不多
授权整个网段可访问nfs       10.0.0.20/24        其中24等同于255.255.255.0，指定网段为生产环境中常用配置
授权某个域名的客户端访问    nfs.dean.com         一般不用，不安全
授权整个域名客户端访问      *.dean.com         一般不用，不安全

生产环境常见配置实例：
常用格式        要共享的目录    客户端ip或ip段(参1，参2...)
配置1           /data/bbs 10.0.0.0/24(rw,sync)
配置2           /home/ryan 10.0.0.0/24(rw,sync,all_squash,anonuid=2000,anongid=2000) 适合多客户端共享一个目录
配置3           /home/dean 10.0.0.15(ro) 只读共享 生产环境中可能用于给开发提供某个测试服务器查看某个正式服务器数据的能力
r读 w写 sync数据同步写入内存和磁盘中


nfs权限配置实例 
服务端共享 /deannfs/dean  给整个192.168.1.0/24 整个网段的主机可读写
[root@6.4-121-server ~]#mkdir -p /deannfs/dean
[root@6.4-121-server ~]#echo '/deannfs/dean 192.168.1.0/24(rw,sync)' >> /etc/exports 
[root@6.4-121-server ~]#/etc/init.d/nfs reload
[root@6.4-121-server ~]#/etc/init.d/iptables stop
iptables: Flushing firewall rules:                         [  OK  ]
iptables: Setting chains to policy ACCEPT: filter          [  OK  ]
iptables: Unloading modules:                               [  OK  ]
[root@6.4-121-server ~]#chmod -R 权限 /deannfs/dean

[dean@6.4-122-client ~]$sudo showmount -e 192.168.1.121
Export list for 192.168.1.121:
/deannfs/dean 192.168.1.0/24
[dean@6.4-122-client ~]$
[dean@6.4-122-client ~]$sudo mount -t nfs 192.168.1.121:/deannfs/dean /opt

centos5版本默认创建文件属主属组为nfsnobody
注意centos6版本较5版本变化了，默认创建共享文件的属主组为nobody，不是nfsnobody,解决办法
使用低版本方式挂载：
mount -t nfs -o vers=3 192.168.1.121:/deannfs/dean /opt
或者修改服务端配置文件 /etc/idmapd.conf,可谷歌，具体修改#Domain = local.domain.edu 取消，注释，设置具体主机名，服务端客户端保持一样

如果觉得nfsnobody 不安全，可以创建一个用户，然后在/etc/exports 里面
/deannfs/dean 192.168.1.121(rw,sync,anonuid=2000,anongid=2000) 
重新加载配置文件 
cat /var/lib/nfs/etab 查看


nfs /etc/exports 参数重点

    rw   可读写
    ro   只读
    sync 请求写入数据时，数据从内存缓存同步写入到nfs server的硬盘后才返回
    async 请求写入数据时，先返回请求，在将数据写入到内存缓存和硬盘中，此参数可以提升nfs性能，但是会降低数据的安全，一般非高并发情况，不建议用
    root_squash 访问nfs server共享目录的用户如果是root的话，它对该共享目录具有root权限，这个配置原本为无盘客户端准备的，应该避免使用！
    root_squash 对于访问nfs server共享目录的用户如果是root的话，则它的权限将被压缩成匿名用户，同时它的uid,gid通常会变成nobody或nfsnobody
    all_squash  不管访问nfs server共享目录的用户身份如何，它的权限都将被压缩成匿名用户，同时它的uid和gid都会变成nobody或nfsnobody,在多个nfs客户端同时读写nfs server数据时，这个参数很有用
    anonuid  参数以anon* 开头即指anonymous匿名用户，这个用户的uid设置值通常为nobody或nfsnobody的uid值，当然我们也可以自行设置这个uid值，但是uid必须存在于/etc/passwd 中，在多个nfs clients时，如多台web server 共享一个nfs目录时，通过这个参数可以使得不同的nfs clients 写入的数据对所有nfs clients 保持同样的用户权限，即为配置的匿名uid对应的权限，这个参数很有用
    anongid 同anonuid 组id设置

提示
    在生产环境中，对于共享的nfs目录，一般客户端挂载不会配置到/etc/fstab里，因为，在客户端主机重启时如果由于网络等原因连接不上nfs server 会导致客户端主机无法启动的厄运，一般通过把mount -t nfs ip:dir 命令放到rc.local中来实现开机自动挂载nfs,不过这也会引起另外问题，就是重启客户端后挂载nfs不成功，要注意
    a. /etc/rc.local  缺点 偶尔开机挂载不上，工作中监控挂载点,建议做法
    b. /etc/fstab     缺点 nfs服务端出于不可用状态，那么客户端开机后可能会导致无法启动的风险，
fstab最后两列，要设置 0 0,也要做挂载点的监控,fstab 最后两列如果设置0 0 就可以避免挂载不上启动不了机器的风险，如果不是0 0就有风险

cat /var/lib/nfs/etab 服务端查看挂载参数
cat /proc/mounts  客户端查看挂载文件的具体参数

技巧 注意项
1. 机器名不要设置成localhost
2. 只读共享ro,不要加sync 只要(ro) 就可以
3. 规范输入信息
4. 主要路径，不要出错
5. 记得开机挂载放到 /etc/rc.local(加注释)，尽量不要放到fstab里，并做挂载点监控
6. 切换root 使用 sudo su - 这样不用输入root密码，工作中也不会给你root密码
7. 每步骤都做检查验证
8. 服务端共享目录时，不能给777权限，修改属主属组为nfsnobody,可读时权限属组都不要动，就默认root就行

nfs排错思路：
no route to host 防火墙问题 经验 
没经验如何检查
    a.ping ip  确定物理链路是否通，高速公路通不通
    b.telnet ip 端口(111)  通不通，设没设收费站

nfs开机自动挂载
1.放在/etc/rc.local 中进行开机自动挂载，建议用
2.放在/etc/fstab里面

    挂载项、目录            本地的挂载点       文件系统类型  挂载选项      备份 磁盘检查 
    tmpfs                   /dev/shm                tmpfs   defaults        0 0
    devpts                  /dev/pts                devpts  gid=5,mode=620  0 0
    sysfs                   /sys                    sysfs   defaults        0 0
    proc                    /proc                   proc    defaults        0 0
    [root@6.4-122-client ~]#

nfs客户端挂载建议
a. 把nfs rpc服务的挂载命令放入/etc/rc.local,然后在通过监控软件监控开机后的挂载情况
b.如果决定把挂载命令放入/etc/fatab里，那么关键是第5,6列的数字要为0，即不备份，不做磁盘检查，同时在监控开机后的挂载情况，最重要的一条是如果fstab做网络nfs系统的开机挂载，那么，rpc服务的开机启动就要用chkconfig来设置，否则，就会导致‘乌龙球’了，系统可能启动不起来了，nfs挂载也不正常

/etc/fstab 详解，每个文件系统占一行，一行6列，默认tab键做分割，空格也行
    第一列 是需要挂载的设备或者远程的文件系统（如nfs）
        此列的格式
            普通挂载  /dev/cdrom
            nfs挂载   <host>:<dir> 如192.168.1.121:/deannfs/dean
            procfs挂载 proc
            LABEL或UUID挂载 LABEL=<label> or UUID=<uuid> 如LABEL=/boot 或UUID=3e6bsdas-8129-asdad....
    第二列 是文件系统在本地的挂载点
            例如把/dev/sdb 挂载到/opt 下，这些就写 /opt,特别说明，man fstab中提到，如果是swap分区的话其挂载点为none，但centos系统装完系统后，发现swap挂载点分区是swap,arclinux 挂载点为none,注意一下即可

    第三列 是要挂载的文件系统类型
            man手册中类型有n种，man mount -t vfstype 参数 查看当前系统内核支持的文件系统可以执行cat /proc/filesystem
    第四列 是文件系统关联的mount选项
            此列挂载项至少包含一个文件系统类型，可以加上其他的符合文件系统类型的相关选项
                noauto  不能被mount -a命令挂载，启动时不自动挂载
                user 允许用户挂载
                owner 所有的设备属主用户可以挂载
                pamconsole
                comment
         man 8 mount -o 后的参数
            注意有的参数是在fstab里才有效
                async（文件系统优化） 所有设置的文件系统I/O的操作都是异步处理，既不会同步写入到磁盘，此参数能提高性能，但会降低数据安全，一般生产环境不建议使用，除非对性能要求高，对数据可靠性不要求的场合，对应sync
                atime（优化项noatime） 在每一次数据访问时，同步更新每次访问的inode时间，是默认选项，在高并发情况下，建议通过明确加上noatime，来取消这个默认项，以到达提升IO性能，优化IO目的h对应，noatime
                default  这个缺省值包括rw,suid,dev,exec,auto,nouser,async
                exec,允许执行二进制文件  对应noexec，使用noexec时,像shell,php这样的程序也是不能执行的,但通过 sh test.sh 这样的方式还是能执行的，/opt/test.sh方式无法执行
                nodiratime 目录时间戳不更新
                noauto，对应auto 可以被mount -a 自动挂载
                noexec
                suid
                user nouser 
                nosuid 禁止一个普通用户挂载该文件系统，默认挂载的默认选项
                remount  尝试从新挂载一个已经挂载了的文件系统，通常被用于来改变一个文件系统的挂载标志，从而使得一个只读文件系统的可写，这个动作不会改变设备或挂载点，当系统进入故障时，进入single或rsscue模式修复系统时，会发现根文件系统会变成只读文件系统，不允许修改，此时，此命令就有用了，mount -o remount,rw / 将根文件系统重新挂载，修复时这个命令很重要
                ro 挂载一个只读文件系统
                rw 读写
               优化参数 图10 图11   图12
    第五列 通过设置数字0或者1 来决定文件系统是否需要（检查）dump
            0表示不需要dump (dump是linux系统的的备份命令)
    第六列 通过设置数字0或者1 来控制是否在开机进行fsck检查
            0为不检查，根分区一定设置为1，/boot 一般设置为2,如果设置了1是执fsck -A
技巧： 对于本地文件系统一般放在fstab里面做挂载，并且结尾的两列不要用1   1，用0  0
强调：
开机过程是/ect/fstab 先于/etc/rc.local 加载，所以如果先执行fstab,并设置了1 1，此时rc.local没执行，rpcbind没启动呢，所以会起不来，造成风险，建议放到rc.local或者放到fstab时设置 0 0，并将rpcbind开机启动使用chkconfig方式设置

    遇到这种情况有两类
        1.提示你输入用户名密码进行维护，此时默认/etc/fstab是只读的，需要mount -o rw,remount /,之后才能编辑/etc/fstab
        2.无法输入用户名密码等任何信息，此时使用u盘引导修复

nfs及 mount优化
    a.安全优化挂载参数
        mount -t nfs -o nosuid,noexec,nodev,rw 192.168.1.121:/deannfs/dean /opt 命令行使用，fstab也能用，也生效，网络文件系统和本地文件系统效果也是一样的
        (dd 可以模拟建一个磁盘进行挂载测试)
    b.性能调优参数
        rsize,wrise(6.4下默认为65536 已经做了优化，cat /proc/mounts 查看，数值较小的话就需要优化) 图13,
        noatime,nodiratime

企业生产环境nfs性能优化挂载的例子
mount -t nfs -o nosuid,noexec,nodev,noatime,nodiratime,intr,rsize=65536,wsize=65536 192.168.1.121:/deannfs/dean /mnt
如果是本地的文件系统
mount /dev/sdb1 /mnt -o defaults,async,noatime,nodiratime,data=writeback,barrier=0 提示，nodiratime有可能报错       





